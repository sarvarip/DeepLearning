{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files:  ['Aegerolysin.txt', 'Aerolysin.txt', 'Anemone_cytotox.txt', 'Bac_thur_toxin.txt', 'BB_PF.txt', 'Binary_toxB_2.txt', 'Clenterotox.txt', 'Colicin.txt', 'Endotoxin_C.txt', 'ETX_MTX2.txt', 'FB_lectin.txt', 'Gasdermin.txt', 'Hemolysin_N.txt', 'HlyE.txt', 'Leukocidin.txt', 'MACPF.txt', 'PlyB_C.txt', 'PorB.txt', 'T4BSS_DotI_IcmL.txt', 'Tcda_Tcdb_pore.txt', 'Thiol_cytolysin.txt', 'Toxin_Tolip.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dirpath = './Pfam_info'\n",
    "print('Available files: ', os.listdir(dirpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_files = []\n",
    "for file in os.listdir(dirpath):\n",
    "    f = './Pfam_info/' + file\n",
    "    in_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Pfam_info/Aegerolysin.txt',\n",
       " './Pfam_info/Aerolysin.txt',\n",
       " './Pfam_info/Anemone_cytotox.txt',\n",
       " './Pfam_info/Bac_thur_toxin.txt',\n",
       " './Pfam_info/BB_PF.txt',\n",
       " './Pfam_info/Binary_toxB_2.txt',\n",
       " './Pfam_info/Clenterotox.txt',\n",
       " './Pfam_info/Colicin.txt',\n",
       " './Pfam_info/Endotoxin_C.txt',\n",
       " './Pfam_info/ETX_MTX2.txt',\n",
       " './Pfam_info/FB_lectin.txt',\n",
       " './Pfam_info/Gasdermin.txt',\n",
       " './Pfam_info/Hemolysin_N.txt',\n",
       " './Pfam_info/HlyE.txt',\n",
       " './Pfam_info/Leukocidin.txt',\n",
       " './Pfam_info/MACPF.txt',\n",
       " './Pfam_info/PlyB_C.txt',\n",
       " './Pfam_info/PorB.txt',\n",
       " './Pfam_info/T4BSS_DotI_IcmL.txt',\n",
       " './Pfam_info/Tcda_Tcdb_pore.txt',\n",
       " './Pfam_info/Thiol_cytolysin.txt',\n",
       " './Pfam_info/Toxin_Tolip.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(in_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [04:10<00:00, 11.38s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_structures = 0\n",
    "labels = []\n",
    "\n",
    "for filename in tqdm(in_files):\n",
    "    \n",
    "    #PART I\n",
    "    \n",
    "    pdbid = []\n",
    "    chain = []\n",
    "    pdbres = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        total = len(lines)\n",
    "        dummy_pdbid = []\n",
    "        dummy_chain = []\n",
    "        dummy_pdbres = []\n",
    "        count = 1\n",
    "        for line in lines:\n",
    "            elements = line.split('\\t')\n",
    "            if len(elements) == 3: #when we have only three columns, the only difference is the chain ID, the uniprot ID \n",
    "                #and the PDB id are the same, so we do not create a new array (inside the big array), but we just append\n",
    "                dummy_pdbid.append(dummy_pdbid[-1])\n",
    "                dummy_chain.append(elements[0])\n",
    "                start = elements[1].split('-')[0]\n",
    "                end = elements[1].split('-')[1]\n",
    "                dummy_pdbres.append((int(start.strip()),int(end.strip())))\n",
    "            elif len(elements) == 4: #NOW EACH NEW PDB ID (ENTRY) WILL COUNT EVEN IF FOR SAME UNIPROT SEQ\n",
    "                #CAN BE EASILY CHANGED BY REVERTING TO STRUCTURE ABOVE (SEE LEN(ELEMENTS)==3 STRUCTURE)\n",
    "                if len(dummy_pdbid) != 0:\n",
    "                    pdbid.append(dummy_pdbid)\n",
    "                    chain.append(dummy_chain)\n",
    "                    pdbres.append(dummy_pdbres)\n",
    "                    dummy_pdbid = []\n",
    "                    dummy_chain = []\n",
    "                    dummy_pdbres = []\n",
    "                dummy_pdbid.append(elements[0])\n",
    "                dummy_chain.append(elements[1])\n",
    "                start = elements[2].split('-')[0]\n",
    "                end = elements[2].split('-')[1]\n",
    "                dummy_pdbres.append((int(start.strip()),int(end.strip())))\n",
    "            elif len(elements) == 5: #NOW EACH NEW PDB ENTRY WILL COUNT EVEN IF FOR SAME UNIPROT SEQ\n",
    "                #LEN 5 HAPPENS WHEN MULTIPLE DOMAIN OF THE SAME UNIPROT ENTRY ARE IN FAMILY\n",
    "                #https://pfam.xfam.org/family/aerolysin#tabview=tab9\n",
    "                if len(dummy_pdbid) != 0:\n",
    "                    pdbid.append(dummy_pdbid)\n",
    "                    chain.append(dummy_chain)\n",
    "                    pdbres.append(dummy_pdbres)\n",
    "                    dummy_pdbid = []\n",
    "                    dummy_chain = []\n",
    "                    dummy_pdbres = []\n",
    "                dummy_pdbid.append(elements[1])\n",
    "                dummy_chain.append(elements[2])\n",
    "                start = elements[3].split('-')[0]\n",
    "                end = elements[3].split('-')[1]\n",
    "                dummy_pdbres.append((int(start.strip()),int(end.strip())))\n",
    "            elif len(elements) == 6:\n",
    "                if len(dummy_pdbid) != 0:\n",
    "                    pdbid.append(dummy_pdbid)\n",
    "                    chain.append(dummy_chain)\n",
    "                    pdbres.append(dummy_pdbres)\n",
    "                    dummy_pdbid = []\n",
    "                    dummy_chain = []\n",
    "                    dummy_pdbres = []\n",
    "                dummy_pdbid.append(elements[2])\n",
    "                dummy_chain.append(elements[3])\n",
    "                start = elements[4].split('-')[0]\n",
    "                end = elements[4].split('-')[1]\n",
    "                dummy_pdbres.append((int(start.strip()),int(end.strip())))\n",
    "            else:\n",
    "                print(len(elements))\n",
    "                print(line)\n",
    "            if (count == total):\n",
    "                pdbid.append(dummy_pdbid)\n",
    "                chain.append(dummy_chain)\n",
    "                pdbres.append(dummy_pdbres)\n",
    "            count = count + 1\n",
    "   \n",
    "    #PART II\n",
    "    #totally could do binary search since ss.txt is in order\n",
    "\n",
    "    array = []\n",
    "    for i, j in zip(pdbid, chain):\n",
    "        dummy = []\n",
    "        for k,l in zip(i, j):\n",
    "            dummy.append(\">\"+k+\":\"+l+\":sequence\")\n",
    "        array.append(dummy)\n",
    "\n",
    "    mapfile = open(\"ss.txt\", \"r\")\n",
    "    maplines = mapfile.readlines()\n",
    "    \n",
    "    structures = []\n",
    "    #idxes_1 = []\n",
    "    #idxes_2 = []\n",
    "    for uniprot in array: #what this is doing is chosing an array from a nested array and the chosen array corresponds \n",
    "        #to a new PDB ID with many different chain IDs and the one added to labels is the one found first in ss.txt\n",
    "        idx_1 = array.index(uniprot)\n",
    "        structure = []\n",
    "        count = 0\n",
    "        total_length = len(maplines)\n",
    "        for line in maplines:\n",
    "            if line.strip() in uniprot:\n",
    "                #print(line.strip())\n",
    "                idx_2 = uniprot.index(line.strip())\n",
    "                #idxes_1.append(idx_1)\n",
    "                #idxes_2.append(idx_2)\n",
    "                labels.append(array[idx_1][idx_2][1:7])\n",
    "                while not (maplines[count+1].startswith(\">\")):\n",
    "                    structure.append(maplines[count+1].strip())\n",
    "                    count = count + 1\n",
    "                structures.append(''.join(structure))\n",
    "                break;\n",
    "            #if count == total_length-1:\n",
    "                #print(\"In file: \", filename, \" Entry: \", uniprot, \" was not found in mapping file!\")\n",
    "            count = count + 1\n",
    "    mapfile.close()\n",
    "    length = len(structures)\n",
    "    \n",
    "    #PFAM PDB DOMAIN ANNOTATION IS WRONG\n",
    "    #https://pfam.xfam.org/family/PF03944#tabview=tab9\n",
    "    #LAST ENTRY 4D8M HAS PDB RESIDUE 697 IN DOMAIN, BUT\n",
    "    #4D8M IS ONLY 587 LONG! \n",
    "    #https://www.rcsb.org/structure/4d8m\n",
    "    \n",
    "    #not using idxes, but checking all different pdb structures \n",
    "    #(we do not differentiate between chains)\n",
    "    #even if it cannot be found in ss.txt\n",
    "    #see how to use idxes in test.ipynb\n",
    "    \n",
    "    res = []\n",
    "    pdbchain = []\n",
    "    pdbentry = []\n",
    "    for i in range(len(pdbid)):\n",
    "        chosen_res = pdbres[i][0]\n",
    "        chosen_entry = pdbid[i][0]\n",
    "        chosen_chain = chain[i][0]\n",
    "        res.append(chosen_res)\n",
    "        pdbchain.append(chosen_chain)\n",
    "        pdbentry.append(chosen_entry)\n",
    "        \n",
    "    info = []\n",
    "    for q,w,e in zip(pdbentry, pdbchain, res):\n",
    "        text = q + ' ' + w + ' ' + ':'.join([str(num) for num in e])\n",
    "        info.append(text)\n",
    "    \n",
    "    file_out = './structures/posAAsequences_' + filename.split('/')[-1]\n",
    "    with open(file_out, 'w+') as result_file:\n",
    "        result_file.write('\\n'.join(structures))\n",
    "        \n",
    "    num_structures += length\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1NTN:A'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[0][0][1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = \"./\" + \"pos_pdb_ids\" + \".pickle\"\n",
    "output = open(path, 'w+b')\n",
    "pickle.dump(labels, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
