{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Example 1 - RAG on NASA book text**"
      ],
      "metadata": {
        "id": "acMAzE9teNwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://learn.microsoft.com/en-us/azure/search/tutorial-rag-build-solution-pipeline"
      ],
      "metadata": {
        "id": "T8pN8NeQQ-i0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Azure-Samples/azure-search-openai-demo/issues/290"
      ],
      "metadata": {
        "id": "s-EKE2neujgo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlt0h4XAEFVB",
        "outputId": "e31c1f1d-8de4-48b3-a860-eda451dea5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.7/297.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/197.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.6/405.6 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.1/113.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "! pip install python-dotenv azure-core azure-search-documents==11.5.1 azure-storage-blob azure-identity openai aiohttp --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AZURE_SEARCH_SERVICE: str = \"\"\n",
        "AZURE_SEARCH_KEY: str = \"\"\n",
        "AZURE_OPENAI_ACCOUNT: str = \"\"\n",
        "AZURE_OPENAI_KEY: str = \"\"\n",
        "AZURE_AI_MULTISERVICE_ACCOUNT: str = \"\"\n",
        "AZURE_AI_MULTISERVICE_KEY: str = \"\"\n",
        "AZURE_STORAGE_CONNECTION: str = \"\""
      ],
      "metadata": {
        "id": "7Jox6dvSE-0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.search.documents.indexes import SearchIndexClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    SearchField,\n",
        "    SearchFieldDataType,\n",
        "    VectorSearch,\n",
        "    HnswAlgorithmConfiguration,\n",
        "    VectorSearchProfile,\n",
        "    AzureOpenAIVectorizer,\n",
        "    AzureOpenAIVectorizerParameters,\n",
        "    SearchIndex\n",
        ")\n",
        "\n",
        "AZURE_SEARCH_CREDENTIAL = AzureKeyCredential(AZURE_SEARCH_KEY)\n",
        "\n",
        "# Create a search index\n",
        "index_name = \"py-rag-tutorial-idx\"\n",
        "index_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "fields = [\n",
        "    SearchField(name=\"parent_id\", type=SearchFieldDataType.String),\n",
        "    SearchField(name=\"title\", type=SearchFieldDataType.String),\n",
        "    SearchField(name=\"locations\", type=SearchFieldDataType.Collection(SearchFieldDataType.String), filterable=True),\n",
        "    SearchField(name=\"chunk_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True, analyzer_name=\"keyword\"),\n",
        "    SearchField(name=\"chunk\", type=SearchFieldDataType.String, sortable=False, filterable=False, facetable=False),\n",
        "    SearchField(name=\"text_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), vector_search_dimensions=1536, vector_search_profile_name=\"myHnswProfile\")\n",
        "    ]\n",
        "\n",
        "# Configure the vector search configuration\n",
        "vector_search = VectorSearch(\n",
        "    algorithms=[\n",
        "        HnswAlgorithmConfiguration(name=\"myHnsw\"),\n",
        "    ],\n",
        "    profiles=[\n",
        "        VectorSearchProfile(\n",
        "            name=\"myHnswProfile\",\n",
        "            algorithm_configuration_name=\"myHnsw\",\n",
        "            vectorizer_name=\"myOpenAI\",\n",
        "        )\n",
        "    ],\n",
        "    vectorizers=[\n",
        "        AzureOpenAIVectorizer(\n",
        "            vectorizer_name=\"myOpenAI\",\n",
        "            kind=\"azureOpenAI\",\n",
        "            parameters=AzureOpenAIVectorizerParameters(\n",
        "                resource_url=AZURE_OPENAI_ACCOUNT,\n",
        "                deployment_name=\"text-embedding-ada-002\",\n",
        "                model_name=\"text-embedding-ada-002\",\n",
        "                api_key=AZURE_OPENAI_KEY\n",
        "            ),\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Create the search index\n",
        "index = SearchIndex(name=index_name, fields=fields, vector_search=vector_search)\n",
        "result = index_client.create_or_update_index(index)\n",
        "print(f\"{result.name} created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D9RdherJpEX",
        "outputId": "3db2ef4c-56e7-46bb-e054-3d97c0bb5309"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "py-rag-tutorial-idx created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes import SearchIndexerClient\n",
        "from azure.search.documents.indexes.models import (\n",
        "    SearchIndexerDataContainer,\n",
        "    SearchIndexerDataSourceConnection\n",
        ")\n",
        "\n",
        "# Create a data source\n",
        "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "container = SearchIndexerDataContainer(name=\"nasa-ebook-pdfs-all\")\n",
        "data_source_connection = SearchIndexerDataSourceConnection(\n",
        "    name=\"py-rag-tutorial-ds\",\n",
        "    type=\"azureblob\",\n",
        "    connection_string=AZURE_STORAGE_CONNECTION,\n",
        "    container=container\n",
        ")\n",
        "data_source = indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
        "\n",
        "print(f\"Data source '{data_source.name}' created or updated\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud6u3BfYJz1K",
        "outputId": "2fbad5e3-64e4-47b5-f146-690f7c53978c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source 'py-rag-tutorial-ds' created or updated\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes.models import (\n",
        "    SplitSkill,\n",
        "    InputFieldMappingEntry,\n",
        "    OutputFieldMappingEntry,\n",
        "    AzureOpenAIEmbeddingSkill,\n",
        "    EntityRecognitionSkill,\n",
        "    SearchIndexerIndexProjection,\n",
        "    SearchIndexerIndexProjectionSelector,\n",
        "    SearchIndexerIndexProjectionsParameters,\n",
        "    IndexProjectionMode,\n",
        "    SearchIndexerSkillset,\n",
        "    CognitiveServicesAccountKey\n",
        ")\n",
        "\n",
        "# Create a skillset\n",
        "skillset_name = \"py-rag-tutorial-ss\"\n",
        "\n",
        "split_skill = SplitSkill(\n",
        "    description=\"Split skill to chunk documents\",\n",
        "    text_split_mode=\"pages\",\n",
        "    context=\"/document\",\n",
        "    maximum_page_length=2000,\n",
        "    page_overlap_length=500,\n",
        "    inputs=[\n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/content\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        OutputFieldMappingEntry(name=\"textItems\", target_name=\"pages\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "embedding_skill = AzureOpenAIEmbeddingSkill(\n",
        "    description=\"Skill to generate embeddings via Azure OpenAI\",\n",
        "    context=\"/document/pages/*\",\n",
        "    resource_url=AZURE_OPENAI_ACCOUNT,\n",
        "    deployment_name=\"text-embedding-ada-002\",\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        "    dimensions=1536,\n",
        "    inputs=[\n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\"),\n",
        "    ],\n",
        "    outputs=[\n",
        "        OutputFieldMappingEntry(name=\"embedding\", target_name=\"text_vector\")\n",
        "    ],\n",
        ")\n",
        "\n",
        "entity_skill = EntityRecognitionSkill(\n",
        "    description=\"Skill to recognize entities in text\",\n",
        "    context=\"/document/pages/*\",\n",
        "    categories=[\"Location\"],\n",
        "    default_language_code=\"en\",\n",
        "    inputs=[\n",
        "        InputFieldMappingEntry(name=\"text\", source=\"/document/pages/*\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        OutputFieldMappingEntry(name=\"locations\", target_name=\"locations\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "index_projections = SearchIndexerIndexProjection(\n",
        "    selectors=[\n",
        "        SearchIndexerIndexProjectionSelector(\n",
        "            target_index_name=index_name,\n",
        "            parent_key_field_name=\"parent_id\",\n",
        "            source_context=\"/document/pages/*\",\n",
        "            mappings=[\n",
        "                InputFieldMappingEntry(name=\"chunk\", source=\"/document/pages/*\"),\n",
        "                InputFieldMappingEntry(name=\"text_vector\", source=\"/document/pages/*/text_vector\"),\n",
        "                InputFieldMappingEntry(name=\"locations\", source=\"/document/pages/*/locations\"),\n",
        "                InputFieldMappingEntry(name=\"title\", source=\"/document/metadata_storage_name\"),\n",
        "            ],\n",
        "        ),\n",
        "    ],\n",
        "    parameters=SearchIndexerIndexProjectionsParameters(\n",
        "        projection_mode=IndexProjectionMode.SKIP_INDEXING_PARENT_DOCUMENTS\n",
        "    ),\n",
        ")\n",
        "\n",
        "cognitive_services_account = CognitiveServicesAccountKey(key=AZURE_AI_MULTISERVICE_KEY)\n",
        "\n",
        "skills = [split_skill, embedding_skill, entity_skill]\n",
        "\n",
        "skillset = SearchIndexerSkillset(\n",
        "    name=skillset_name,\n",
        "    description=\"Skillset to chunk documents and generating embeddings\",\n",
        "    skills=skills,\n",
        "    index_projection=index_projections,\n",
        "    cognitive_services_account=cognitive_services_account\n",
        ")\n",
        "\n",
        "client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "client.create_or_update_skillset(skillset)\n",
        "print(f\"{skillset.name} created\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoWQd0HEKQtD",
        "outputId": "887bae67-1db3-4d21-db11-5ece923dfecc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "py-rag-tutorial-ss created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents.indexes.models import (\n",
        "    SearchIndexer,\n",
        "    FieldMapping\n",
        ")\n",
        "\n",
        "# Create an indexer\n",
        "indexer_name = \"py-rag-tutorial-idxr\"\n",
        "\n",
        "indexer_parameters = None\n",
        "\n",
        "indexer = SearchIndexer(\n",
        "    name=indexer_name,\n",
        "    description=\"Indexer to index documents and generate embeddings\",\n",
        "    skillset_name=skillset_name,\n",
        "    target_index_name=index_name,\n",
        "    data_source_name=data_source.name,\n",
        "    # Map the metadata_storage_name field to the title field in the index to display the PDF title in the search results\n",
        "    field_mappings=[FieldMapping(source_field_name=\"metadata_storage_name\", target_field_name=\"title\")],\n",
        "    parameters=indexer_parameters\n",
        ")\n",
        "\n",
        "# Create and run the indexer\n",
        "indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL)\n",
        "indexer_result = indexer_client.create_or_update_indexer(indexer)\n",
        "\n",
        "print(f' {indexer_name} is created and running. Give the indexer a few minutes before running a query.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjMFGMqeMH-y",
        "outputId": "84eeffce-dc1d-4383-e22f-d7b998a1e39c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " py-rag-tutorial-idxr is created and running. Give the indexer a few minutes before running a query.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import VectorizableTextQuery\n",
        "\n",
        "# Vector Search using text-to-vector conversion of the querystring\n",
        "query = \"where are NASA's headquarters located?\"\n",
        "\n",
        "search_client = SearchClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL, index_name=index_name)\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"text_vector\", exhaustive=True)\n",
        "\n",
        "results = search_client.search(\n",
        "    search_text=query,\n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"title\", \"chunk\", \"locations\"],\n",
        "    top=1\n",
        ")\n",
        "\n",
        "for result in results:\n",
        "    print(f\"Score: {result['@search.score']}\")\n",
        "    print(f\"Title: {result['title']}\")\n",
        "    print(f\"Locations: {result['locations']}\")\n",
        "    print(f\"Content: {result['chunk']}\")"
      ],
      "metadata": {
        "id": "m23-EdiMO3nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7c25ad-0d92-4d46-f61e-221e882de14c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.03333333507180214\n",
            "Title: page-178.pdf\n",
            "Locations: ['Headquarters', 'Washington']\n",
            "Content: national Aeronautics and Space Administration\n",
            "\n",
            "earth Science\n",
            "\n",
            "NASA Headquarters \n",
            "\n",
            "300 E Street SW \n",
            "\n",
            "Washington, DC 20546\n",
            "\n",
            "www.nasa.gov\n",
            "\n",
            "np-2018-05-2546-hQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.search.documents import SearchClient\n",
        "from azure.search.documents.models import VectorizableTextQuery\n",
        "\n",
        "# Vector Search using text-to-vector conversion of the querystring\n",
        "query = \"what is a sweet fruit in UAE?\"\n",
        "\n",
        "search_client = SearchClient(endpoint=AZURE_SEARCH_SERVICE, credential=AZURE_SEARCH_CREDENTIAL, index_name=index_name)\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"text_vector\", exhaustive=True)\n",
        "\n",
        "results = search_client.search(\n",
        "    search_text=query,\n",
        "    vector_queries= [vector_query],\n",
        "    select=[\"parent_id\", \"chunk_id\", \"title\", \"chunk\", \"locations\"],\n",
        "    top=1\n",
        ")\n",
        "\n",
        "for result in results:\n",
        "    print(f\"Score: {result['@search.score']}\")\n",
        "    print(f\"Title: {result['title']}\")\n",
        "    print(f\"Locations: {result['locations']}\")\n",
        "    print(f\"Content: {result['chunk']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EMO5eqfK8rJ",
        "outputId": "0376fcad-f3cf-4666-9c97-20e66053d7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.030365297570824623\n",
            "Title: page-117.pdf\n",
            "Locations: ['United Arab Emirates', 'Rub’ al Khali', 'desert', 'plantations', 'towns', 'Liwa Oasis', 'Abu Dhabi', 'Arabian Peninsula', 'farms', 'greenhouses', 'aquifers', 'sand seas']\n",
            "Content: L\n",
            "a\n",
            "\n",
            "n\n",
            "d\n",
            "\n",
            "E\n",
            "A\n",
            "\n",
            "R\n",
            "T\n",
            "\n",
            "H\n",
            "\n",
            "110\n",
            "\n",
            "Liwa Oasis\n",
            "United Arab Emirates\n",
            "\n",
            "In the sandy tan terrain of the United Arab Emirates, on the northern edge of the Rub’ al Khali, an oasis brings green to the desert. \n",
            "\n",
            "The T-shaped, 100-kilometer stretch of date plantations and small towns compose the Liwa Oasis, home to about 20,000 people in \n",
            "\n",
            "the emirate of Abu Dhabi. It is one of the largest oases on the Arabian Peninsula.\n",
            "\n",
            "Bedouins tapped underground water supplies here at least five centuries ago, and date farms have proliferated. Drip irrigation \n",
            "\n",
            "and greenhouses now help conserve the precious water supply. Since rainfall is scarce in the region, much of the water comes \n",
            "\n",
            "from aquifers full of “fossil” water that accumulated more than 20,000 years ago and is now buried deep under the sand seas and \n",
            "\n",
            "limestone formations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from azure.search.documents import SearchClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "# Set up clients and specify the chat model\n",
        "openai_client = AzureOpenAI(\n",
        "     api_version=\"2024-06-01\",\n",
        "     azure_endpoint=AZURE_OPENAI_ACCOUNT,\n",
        "     api_key=AZURE_OPENAI_KEY\n",
        " )\n",
        "\n",
        "deployment_name = \"gpt-4o\"\n",
        "\n",
        "search_client = SearchClient(\n",
        "     endpoint=AZURE_SEARCH_SERVICE,\n",
        "     index_name=index_name,\n",
        "     credential=AZURE_SEARCH_CREDENTIAL\n",
        " )\n",
        "\n",
        "# Provide instructions to the model\n",
        "GROUNDED_PROMPT=\"\"\"\n",
        "You are a helpful AI assistant.\n",
        "Answer the query using only the sources provided below.\n",
        "Do not generate answers that don't use the sources below.\n",
        "Query: {query}\n",
        "Sources:\\n{sources}\n",
        "\"\"\"\n",
        "\n",
        "# Provide the query. Notice it's sent to both the search engine and the LLM.\n",
        "query=\"What is a sweet fruit in UAE?\"\n",
        "\n",
        "#needs to be added, missed from the demo code!!\n",
        "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=1, fields=\"text_vector\", exhaustive=True)\n",
        "\n",
        "# Set up the search results and the chat thread.\n",
        "# Retrieve the selected fields from the search index related to the question.\n",
        "search_results = search_client.search(\n",
        "    search_text=query,\n",
        "    vector_queries= [vector_query],\n",
        "    top=1,\n",
        "    select=\"title, chunk, locations\"\n",
        ")\n",
        "sources_formatted = \"\\n\".join([f'{document[\"title\"]}:{document[\"chunk\"]}:{document[\"locations\"]}' for document in search_results])\n",
        "\n",
        "response = openai_client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": GROUNDED_PROMPT.format(query=query, sources=sources_formatted)\n",
        "        }\n",
        "    ],\n",
        "    model=deployment_name\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhWhGLEkQz4G",
        "outputId": "335cb249-26fe-42ad-816e-73ebf4d20646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A sweet fruit in the UAE is the date, which is cultivated extensively in the Liwa Oasis located in the emirate of Abu Dhabi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sources_formatted"
      ],
      "metadata": {
        "id": "YwVOtWigSF20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c0ddf720-3624-4774-c1d2-939f40e77327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"page-117.pdf:L\\na\\n\\nn\\nd\\n\\nE\\nA\\n\\nR\\nT\\n\\nH\\n\\n110\\n\\nLiwa Oasis\\nUnited Arab Emirates\\n\\nIn the sandy tan terrain of the United Arab Emirates, on the northern edge of the Rub’ al Khali, an oasis brings green to the desert. \\n\\nThe T-shaped, 100-kilometer stretch of date plantations and small towns compose the Liwa Oasis, home to about 20,000 people in \\n\\nthe emirate of Abu Dhabi. It is one of the largest oases on the Arabian Peninsula.\\n\\nBedouins tapped underground water supplies here at least five centuries ago, and date farms have proliferated. Drip irrigation \\n\\nand greenhouses now help conserve the precious water supply. Since rainfall is scarce in the region, much of the water comes \\n\\nfrom aquifers full of “fossil” water that accumulated more than 20,000 years ago and is now buried deep under the sand seas and \\n\\nlimestone formations.:['United Arab Emirates', 'Rub’ al Khali', 'desert', 'plantations', 'towns', 'Liwa Oasis', 'Abu Dhabi', 'Arabian Peninsula', 'farms', 'greenhouses', 'aquifers', 'sand seas']\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fW2a9rEsNhPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6w2jwa8drJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UfcFQO0flWWC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}